{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBlV2ewmwSJ8",
        "outputId": "f3ddb783-0f02-46a0-dc8d-c38c219c7598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting pyspark==3.4.1\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2) (2024.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285391 sha256=6699598cd65debf8e025f46b350e14b28c734fa73b56fded9f79bd93dd3bd362\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==2.2.2 numpy pyspark==3.4.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pengenalan Spark DataFrames"
      ],
      "metadata": {
        "id": "EolA8lt4w2vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh membuat DataFrame sederhana dan operasi dasar\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan6').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000)]\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw3fAwpkwg2t",
        "outputId": "69d192ac-7a9b-432f-b382-3c9f434057d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+\n",
            "|EmployeeName|Department|Salary|\n",
            "+------------+----------+------+\n",
            "|       James|     Sales|  3000|\n",
            "|     Michael|     Sales|  4600|\n",
            "|      Robert|     Sales|  4100|\n",
            "|       Maria|   Finance|  3000|\n",
            "+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Transformasi Dasar dengan DataFrames"
      ],
      "metadata": {
        "id": "ibWKYmvVw7tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh operasi transformasi DataFrame\n",
        "df.select('EmployeeName', 'Salary').show()\n",
        "df.filter(df['Salary'] > 3000).show()\n",
        "df.groupBy('Department').avg('Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz1Wo0ZDwjHT",
        "outputId": "e7e669a0-b6f1-428f-f6f8-8cc4eebb97be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|EmployeeName|Salary|\n",
            "+------------+------+\n",
            "|       James|  3000|\n",
            "|     Michael|  4600|\n",
            "|      Robert|  4100|\n",
            "|       Maria|  3000|\n",
            "+------------+------+\n",
            "\n",
            "+------------+----------+------+\n",
            "|EmployeeName|Department|Salary|\n",
            "+------------+----------+------+\n",
            "|     Michael|     Sales|  4600|\n",
            "|      Robert|     Sales|  4100|\n",
            "+------------+----------+------+\n",
            "\n",
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3900.0|\n",
            "|   Finance|     3000.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 2: Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."
      ],
      "metadata": {
        "id": "cVnQOsn7xeKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengelompokkan berdasarkan 'Department' dan menghitung rata-rata gaji\n",
        "df.groupBy('Department').avg('Salary').show()\n",
        "\n",
        "# Mengelompokkan berdasarkan 'Department' dan menghitung gaji maksimum\n",
        "df.groupBy('Department').max('Salary').show()\n",
        "\n",
        "# Mengelompokkan berdasarkan 'Department' dan menghitung total gaji\n",
        "df.groupBy('Department').sum('Salary').show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YM5AqkhxiM-",
        "outputId": "d0c960e4-33b7-414a-bb8f-45f9d432df9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3900.0|\n",
            "|   Finance|     3000.0|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|Department|max(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|       4600|\n",
            "|   Finance|       3000|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|Department|sum(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|      11700|\n",
            "|   Finance|       3000|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Bekerja dengan Tipe Data Kompleks"
      ],
      "metadata": {
        "id": "XImvR-Iaw_io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh manipulasi tipe data kompleks\n",
        "# Tambahkan kolom SalaryBonus\n",
        "df_with_bonus = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
        "\n",
        "# Tambahkan kolom TotalCompensation berdasarkan kolom Salary dan SalaryBonus\n",
        "df_with_total_comp = df_with_bonus.withColumn('TotalCompensation', df_with_bonus['Salary'] + df_with_bonus['SalaryBonus'])\n",
        "\n",
        "# Tampilkan hasil akhir\n",
        "df_with_total_comp.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rmz1LKhwnsz",
        "outputId": "e4d1c5cf-4847-4010-fcc8-3721932e3326"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+-----------+-----------------+\n",
            "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "|       James|     Sales|  3000|      300.0|           3300.0|\n",
            "|     Michael|     Sales|  4600|      460.0|           5060.0|\n",
            "|      Robert|     Sales|  4100|      410.0|           4510.0|\n",
            "|       Maria|   Finance|  3000|      300.0|           3300.0|\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 3: Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."
      ],
      "metadata": {
        "id": "9a79J-fuxk8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Array di PySpark\n",
        "\n",
        "from pyspark.sql.functions import array\n",
        "\n",
        "# Membuat kolom baru 'Benefits' yang berupa array dari dua elemen\n",
        "df_with_array = df.withColumn('Benefits', array(df['Salary'], df['Salary'] * 0.2))\n",
        "df_with_array.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSc7Rsubxpfk",
        "outputId": "f102e2f6-4366-440a-fbab-280ef2bd83d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+---------------+\n",
            "|EmployeeName|Department|Salary|Benefits       |\n",
            "+------------+----------+------+---------------+\n",
            "|James       |Sales     |3000  |[3000.0, 600.0]|\n",
            "|Michael     |Sales     |4600  |[4600.0, 920.0]|\n",
            "|Robert      |Sales     |4100  |[4100.0, 820.0]|\n",
            "|Maria       |Finance   |3000  |[3000.0, 600.0]|\n",
            "+------------+----------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Manipulasi Array\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Mengakses elemen pertama dan kedua dari kolom 'Benefits'\n",
        "df_with_array.select(col('EmployeeName'), col('Benefits')[0].alias('SalaryComponent1'), col('Benefits')[1].alias('SalaryComponent2')).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldqLZnDrz_oc",
        "outputId": "a67d8084-e69f-4ff3-c26f-7eb493681211"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------------+----------------+\n",
            "|EmployeeName|SalaryComponent1|SalaryComponent2|\n",
            "+------------+----------------+----------------+\n",
            "|       James|          3000.0|           600.0|\n",
            "|     Michael|          4600.0|           920.0|\n",
            "|      Robert|          4100.0|           820.0|\n",
            "|       Maria|          3000.0|           600.0|\n",
            "+------------+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Struct di PySpark\n",
        "\n",
        "from pyspark.sql.functions import struct\n",
        "\n",
        "# Membuat kolom baru 'EmployeeInfo' yang berisi nama dan departemen sebagai satu struct\n",
        "df_with_struct = df.withColumn('EmployeeInfo', struct(df['EmployeeName'], df['Department']))\n",
        "df_with_struct.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTin-IR0AWC",
        "outputId": "56f7ac73-9ec8-4efe-ec8d-a8191c7717fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+----------------+\n",
            "|EmployeeName|Department|Salary|EmployeeInfo    |\n",
            "+------------+----------+------+----------------+\n",
            "|James       |Sales     |3000  |{James, Sales}  |\n",
            "|Michael     |Sales     |4600  |{Michael, Sales}|\n",
            "|Robert      |Sales     |4100  |{Robert, Sales} |\n",
            "|Maria       |Finance   |3000  |{Maria, Finance}|\n",
            "+------------+----------+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Akses dan Manipulasi Struct\n",
        "\n",
        "# Akses elemen di dalam struct 'EmployeeInfo'\n",
        "df_with_struct.select(col('EmployeeInfo.EmployeeName'), col('EmployeeInfo.Department')).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BvipF6R0K9A",
        "outputId": "6212f20d-d81d-4e6f-fabc-211a4a7ab8f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|EmployeeName|Department|\n",
            "+------------+----------+\n",
            "|       James|     Sales|\n",
            "|     Michael|     Sales|\n",
            "|      Robert|     Sales|\n",
            "|       Maria|   Finance|\n",
            "+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Map di PySpark\n",
        "\n",
        "from pyspark.sql.functions import create_map, lit\n",
        "\n",
        "# Membuat kolom baru 'SalaryInfo' berupa map yang berisi gaji dan bonus\n",
        "df_with_map = df.withColumn('SalaryInfo', create_map(lit('Salary'), df['Salary'], lit('Bonus'), df['Salary'] * 0.1))\n",
        "df_with_map.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB7a9_Xw0Ovf",
        "outputId": "a1b8d055-f300-4bef-cd06-64067784ea95"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+----------------------------------+\n",
            "|EmployeeName|Department|Salary|SalaryInfo                        |\n",
            "+------------+----------+------+----------------------------------+\n",
            "|James       |Sales     |3000  |{Salary -> 3000.0, Bonus -> 300.0}|\n",
            "|Michael     |Sales     |4600  |{Salary -> 4600.0, Bonus -> 460.0}|\n",
            "|Robert      |Sales     |4100  |{Salary -> 4100.0, Bonus -> 410.0}|\n",
            "|Maria       |Finance   |3000  |{Salary -> 3000.0, Bonus -> 300.0}|\n",
            "+------------+----------+------+----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Operasi Data Lanjutan"
      ],
      "metadata": {
        "id": "UVoLvaUpxFHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh menggunakan window functions\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
        "df.withColumn('Rank', F.rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruKf9rHVwqzP",
        "outputId": "c4d0228a-1fa4-4015-c771-aa0a81fbec94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+----+\n",
            "|EmployeeName|Department|Salary|Rank|\n",
            "+------------+----------+------+----+\n",
            "|       Maria|   Finance|  3000|   1|\n",
            "|       James|     Sales|  3000|   1|\n",
            "|      Robert|     Sales|  4100|   2|\n",
            "|     Michael|     Sales|  4600|   3|\n",
            "+------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 4: Implementasikan window function untuk menghitung running totals atau rangkings."
      ],
      "metadata": {
        "id": "CXWhM4ydxrDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Running Total menggunakan sum()\n",
        "\n",
        "# Definisikan window specification untuk running total\n",
        "windowSpec_running_total = Window.partitionBy('Department').orderBy('Salary').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "# Tambahkan kolom 'RunningTotal' yang menghitung total kumulatif gaji\n",
        "df_with_running_total = df.withColumn('RunningTotal', F.sum('Salary').over(windowSpec_running_total))\n",
        "\n",
        "# Tampilkan DataFrame dengan kolom running total\n",
        "df_with_running_total.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFavdwAMxvkk",
        "outputId": "f0422423-025b-4ec0-c168-b7754d883956"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+------------+\n",
            "|EmployeeName|Department|Salary|RunningTotal|\n",
            "+------------+----------+------+------------+\n",
            "|       Maria|   Finance|  3000|        3000|\n",
            "|       James|     Sales|  3000|        3000|\n",
            "|      Robert|     Sales|  4100|        7100|\n",
            "|     Michael|     Sales|  4600|       11700|\n",
            "+------------+----------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Ranking dengan dense_rank()\n",
        "\n",
        "# Tambahkan kolom 'DenseRank' yang menggunakan window function dense_rank\n",
        "df_with_dense_rank = df.withColumn('DenseRank', F.dense_rank().over(windowSpec))\n",
        "\n",
        "# Tampilkan DataFrame dengan kolom dense rank\n",
        "df_with_dense_rank.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1PJtgG90nNl",
        "outputId": "8486dd1f-7060-4061-bded-363350317afd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+---------+\n",
            "|EmployeeName|Department|Salary|DenseRank|\n",
            "+------------+----------+------+---------+\n",
            "|       Maria|   Finance|  3000|        1|\n",
            "|       James|     Sales|  3000|        1|\n",
            "|      Robert|     Sales|  4100|        2|\n",
            "|     Michael|     Sales|  4600|        3|\n",
            "+------------+----------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Menghitung Moving Average\n",
        "\n",
        "# Definisikan window specification untuk moving average\n",
        "windowSpec_moving_avg = Window.partitionBy('Department').orderBy('Salary').rowsBetween(-1, 1)\n",
        "\n",
        "# Tambahkan kolom 'MovingAvg' yang menghitung rata-rata bergerak (moving average)\n",
        "df_with_moving_avg = df.withColumn('MovingAvg', F.avg('Salary').over(windowSpec_moving_avg))\n",
        "\n",
        "# Tampilkan DataFrame dengan kolom moving average\n",
        "df_with_moving_avg.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CeAFg1H0qia",
        "outputId": "b1a01f81-ad0a-4957-ed2e-1c6ffdacfbe8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+---------+\n",
            "|EmployeeName|Department|Salary|MovingAvg|\n",
            "+------------+----------+------+---------+\n",
            "|       Maria|   Finance|  3000|   3000.0|\n",
            "|       James|     Sales|  3000|   3550.0|\n",
            "|      Robert|     Sales|  4100|   3900.0|\n",
            "|     Michael|     Sales|  4600|   4350.0|\n",
            "+------------+----------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Kesimpulan dan Eksplorasi Lebih Lanjut"
      ],
      "metadata": {
        "id": "rO-Elrn-xIkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 5: Buat ringkasan dari semua operasi yang telah dilakukan dan bagaimana teknik ini dapat diterapkan pada proyek data Anda.\n",
        "\n",
        "Jawaban:\n",
        "\n",
        "Operasi yang dilakukan pada PySpark DataFrames meliputi:\n",
        "\n",
        "1. Membuat DataFrame sederhana dan melakukan operasi dasar seperti select(), filter(), dan groupBy() untuk mengekstrak dan menganalisis data.\n",
        "2. Manipulasi tipe data kompleks seperti penambahan kolom dan perhitungan menggunakan fungsi aritmatika.\n",
        "3. Window functions seperti rank(), sum(), dan avg() digunakan untuk perhitungan peringkat, total kumulatif, dan rata-rata bergerak dalam partisi data."
      ],
      "metadata": {
        "id": "KTzTVZXKx1oS"
      }
    }
  ]
}